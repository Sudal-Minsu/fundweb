import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.font_manager as fm
from tqdm import tqdm
from sqlalchemy import create_engine
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import confusion_matrix
from joblib import Parallel, delayed
import multiprocessing as mp
from config import DB_CONFIG

# ------------------- ì„¤ì • -------------------
TRAIN_YEARS = 12
TARGET_PERCENT = 0.02
BACKTEST_START_DATE = pd.to_datetime("2024-07-11")
TEST_PERIOD_DAYS = 300
SEQ_LEN = 5
TRAIN_YEARS = 12
TEST_PERIOD_DAYS = 60
TARGET_PERCENT = 0.01
LEARNING_RATE = 0.001
EPOCHS = 20
BATCH_SIZE = 32
INITIAL_CAPITAL = 100_000_000
BUY_PROB_THRESHOLD = 0.55
SELL_PROB_THRESHOLD = 0.55
TOP_N_FOR_BUY = 3
BOTTOM_N_FOR_SELL_RANK = 190
FEE_RATE = 0.000140527
TAX_RATE = 0.0015
BACKTEST_START_DATE = pd.to_datetime("2024-07-11")
STOCK_NUMBER = 200

# ë³‘ë ¬ ì„¤ì •
N_CORE = max(1, mp.cpu_count() - 1) # N_CORE = 5
CHUNK = 20  # ì›Œì»¤ë‹¹ ë¬¶ì„ ì¢…ëª© ìˆ˜

# í°íŠ¸ ì„¤ì •
font_path = "C:/Windows/Fonts/malgun.ttf"
font_name = fm.FontProperties(fname=font_path).get_name()
plt.rcParams['font.family'] = font_name
plt.rcParams['axes.unicode_minus'] = False

# ì¶œë ¥ í´ë” ì„¤ì •
OUTPUT_DIR = "rule_2_ê²°ê³¼"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ê³ ì • ì‹œë“œ ì„¤ì •
np.random.seed(42)

# ì¥ì¹˜ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

# ------------------- í”¼ì²˜ ì •ì˜ -------------------
STANDARD_COLS = [
    # ìˆ˜ìµë¥ 
    'Close_RET', 
    # ëª¨ë©˜í…€
    'Momentum_5',
    'Momentum_10',
    'Momentum_20', 
    # Disparity
    'Disparity_5',
    'Disparity_5_Slope',
    'Disparity_10',
    'Disparity_20', 
    # MA ê¸°ìš¸ê¸° & ê°­
    'MA_5_slope',
    'MA_20_slope',
    'MA_20_slope_norm',
    'MA5_MA20_gap',
    'MA_std_5_10_20', 
    # ë³€ë™ì„±
    'Volatility_5',
    'Volatility_ratio_5_20', 
    # MACD
    'MACD_Histogram',
    'MACD_Histogram_Slope', 
    # RSI
    'RSI_Slope', 
    # ê±°ì‹œ ì§€í‘œ ë³€í™”ëŸ‰
    'USD_KRW_RET',
    'USD_KRW_Momentum',
    'USD_KRW_DEVIATION',
    'KOSPI_RET',
    'KOSPI_VOLATILITY',
    'KOSDAQ_RET',
    'KOSDAQ_VOLATILITY',
    # ì‹œê°€/ê³ ì € í™œìš©
    'Intraday_Range',
    # ìµœê·¼ ê³ ì /ì €ì  ëŒ€ë¹„
    'Price_vs_high_20d',
    'Price_vs_low_20d',
    # ì‹œì¥ ê°„ ìŠ¤í”„ë ˆë“œ
    'KOSPI_vs_KOSDAQ', 
]

MINMAX_COLS = [
    # ë ˆë²¨ ê°’
    'Close',
    'LogVolume',
    'TradingValue',
    'TradingValue_Ratio', 
    # ìˆ˜ì¤€ ì§€í‘œ
    'RSI_n',
    'KOSPI',
    'KOSDAQ',
    'USD_KRW',
    'USD_KRW_MA_5', 
    # ë°´ë“œ/í™•ë¥ í˜• ì§€í‘œ (0~1 or 0~100)
    'BB_PCT',
    'Stoch_K',
    'Stoch_D', 
    # ì¢…ê°€ì˜ ê³ ì € ë‚´ ìƒëŒ€ ìœ„ì¹˜ (0~1)
    'Close_to_High',
]

BINARY_COLS = [
    # RSI ìƒíƒœ
    'RSI_oversold',
    'RSI_overbought',
    'RSI_normal_zone', 
    # ë‹¨ê¸° ê¸‰ë½, ê±°ë˜ëŸ‰ ê¸‰ì¦, ë³€ë™ì„± ìŠ¤íŒŒì´í¬
    'ShortTerm_Drop',
    'Volume_jump',
    'Volatility_spike',
    # ì €ê°€ê¶Œ ê·¼ì ‘
    'Price_near_low_20d', 
    # MA ëŒíŒŒ
    'Breaks_MA_20',
    'Breaks_MA_5',
    'MA20_above_MA60',
    'Strong_Trend', 
    # í™˜ìœ¨â†“+MACDâ†‘, ê±°ë˜ëŸ‰+MACD ì½¤ë³´, ë³µí•© ë§¤ìˆ˜ ì‹œê·¸ë„
    'USD_down_MACD_up',
    'MACD_cross_up',
    'MACD_cross_down',
    'MACD_bullish_cross',
    'Volume_MACD_Combo',
    'Composite_Bullish_Signal', 
    # ê°­ì—…/ê°­ë‹¤ìš´
    'Gap_Up',
    'Gap_Down',
    # ìº”ë“¤ íŒ¨í„´
    'Bullish_Candle',
    'Bearish_Candle',
    # ì¶”ê°€ MACD, ë°˜ë“± ê°ì§€
    'MACD_histogram_above_zero', 
    'Rebound_from_low', 
]
CONTINUOUS_COLS = STANDARD_COLS + MINMAX_COLS 
FEATURE_COLUMNS = CONTINUOUS_COLS + BINARY_COLS

# ------------------- DB & ë°ì´í„° ë¡œë”© -------------------
def get_engine():
    return create_engine(
        f"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
    )

def load_stock_data(code, engine):
    q = f"SELECT Date, Open, High, Low, Close, Volume FROM stock_data WHERE Code='{code}' ORDER BY Date"
    df = pd.read_sql(q, engine, parse_dates=['Date'])
    df['Code'] = code
    return df

def load_market_index(engine):
    q = "SELECT Date, IndexType, Close FROM market_index"
    df = pd.read_sql(q, engine, parse_dates=['Date'])
    return df.pivot(index='Date', columns='IndexType', values='Close').reset_index()

# ------------------- ì§€í‘œ ê³„ì‚° -------------------
def compute_rsi(series, period):
    delta = series.diff()
    gain = delta.where(delta > 0, 0).rolling(period).mean()
    loss = -delta.where(delta < 0, 0).rolling(period).mean()
    rs = gain / loss
    return (100 - 100/(1+rs)).fillna(0)

# ------------------- ì „ì²˜ë¦¬ ê³µí†µ -------------------
def engineer_features(df):
    # --- ê¸°ë³¸ ì •ë¦¬ ---
    df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce').fillna(0)
    df['LogVolume'] = np.log1p(df['Volume'])
    df['TradingValue'] = df['Close'] * df['Volume']
    df['Close'] = df['Close']
    df['Close_RET'] = df['Close'].pct_change().fillna(0)

    # --- ê±°ì‹œ ê²½ì œ ë³€ìˆ˜ ì „ì²˜ë¦¬ ---
    df[['KOSPI','KOSDAQ','USD_KRW','US_RATE']] = df[['KOSPI','KOSDAQ','USD_KRW','US_RATE']].ffill().fillna(0)
    df['USD_KRW_RET'] = df['USD_KRW'].pct_change().fillna(0)
    df['USD_KRW_MA_5'] = df['USD_KRW'].rolling(5).mean().fillna(0)
    df['USD_KRW_DEVIATION'] = (df['USD_KRW'] - df['USD_KRW_MA_5']) / df['USD_KRW_MA_5']
    df['USD_KRW_Momentum'] = df['USD_KRW'].pct_change(3).fillna(0)
    df['KOSPI_RET'] = df['KOSPI'].pct_change().fillna(0)
    df['KOSDAQ_RET'] = df['KOSDAQ'].pct_change().fillna(0)
    df['KOSPI_VOLATILITY'] = df['KOSPI'].rolling(5).std().fillna(0)
    df['KOSDAQ_VOLATILITY'] = df['KOSDAQ'].rolling(5).std().fillna(0)
    df['KOSPI_vs_KOSDAQ'] = df['KOSPI_RET'] - df['KOSDAQ_RET']

    # --- ê±°ë˜ëŸ‰ ê¸°ë°˜ ---
    df['TradingValue_Ratio'] = df['TradingValue'] / df['TradingValue'].rolling(5).mean()
    df['Volume_jump'] = (df['Volume'] > df['Volume'].rolling(20).mean() * 1.5).astype(int)

    # --- ëª¨ë©˜í…€ ---
    df['Momentum_5'] = df['Close'] / df['Close'].shift(5) - 1
    df['Momentum_10'] = df['Close'] / df['Close'].shift(10) - 1
    df['Momentum_20'] = df['Close'] / df['Close'].shift(20) - 1

    # --- ë‹¨ê¸° ë‚™í­ ë° ì €ê°€ ê·¼ì ‘ ---
    df['ShortTerm_Drop'] = (df['Close'].pct_change(1) < -0.02).astype(int)
    df['Price_near_low_20d'] = (df['Close'] < df['Close'].rolling(20).min() * 1.05).astype(int)
    df['Price_vs_high_20d'] = df['Close'] / df['Close'].rolling(20).max() - 1
    df['Price_vs_low_20d'] = df['Close'] / df['Close'].rolling(20).min() - 1

    # --- ë³€ë™ì„± ---
    df['Volatility_5'] = df['Close'].rolling(5).std().fillna(0)
    df['Volatility_spike'] = (df['Volatility_5'] > df['Volatility_5'].rolling(30).mean()).astype(int)
    df['Volatility_ratio_5_20'] = df['Volatility_5'] / df['Close'].rolling(20).std()

    # --- ì´ë™ í‰ê·  / ì¶”ì„¸ ---
    df['MA_5'] = df['Close'].rolling(5).mean()
    df['MA_10'] = df['Close'].rolling(10).mean()
    df['MA_20'] = df['Close'].rolling(20).mean()
    df['MA_60'] = df['Close'].rolling(60).mean()
    df['Disparity_5'] = df['Close'] / df['Close'].rolling(5).mean() - 1
    df['Disparity_10'] = df['Close'] / df['Close'].rolling(10).mean() - 1
    df['Disparity_20'] = df['Close'] / df['Close'].rolling(20).mean() - 1
    df['Disparity_5_Slope'] = df['Disparity_5'].diff().fillna(0)
    df['MA_20_slope'] = df['MA_20'].diff().fillna(0)
    df['MA_5_slope'] = df['Close'].rolling(5).mean().diff().fillna(0)
    df['MA_20_slope_norm'] = df['MA_20_slope'] / df['MA_20'].shift(1)
    df['MA5_MA20_gap'] = df['Close'].rolling(5).mean() / df['MA_20'] - 1
    df['MA_std_5_10_20'] = df[['MA_5', 'MA_10', 'MA_20']].std(axis=1)
    df['Breaks_MA_20'] = (df['Close'] > df['MA_20']).astype(int)
    df['Breaks_MA_5'] = (df['Close'] > df['Close'].rolling(5).mean()).astype(int)
    df['MA20_above_MA60'] = (df['MA_20'] > df['MA_60']).astype(int)
    df['Strong_Trend'] = ((df['MA_5_slope'] > 0) & (df['MA20_above_MA60'] == 1)).astype(int)

    # --- RSI ---
    df['RSI_n'] = compute_rsi(df['Close'], 2)
    df['RSI_Slope'] = df['RSI_n'].diff().fillna(0)
    df['RSI_normal_zone'] = ((df['RSI_n'] >= 30) & (df['RSI_n'] <= 70)).astype(int)
    df['RSI_oversold'] = (df['RSI_n'] < 30).astype(int)
    df['RSI_overbought'] = (df['RSI_n'] > 70).astype(int)

    # --- MACD ---
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD_Line'] = df['EMA12'] - df['EMA26']
    df['Signal_Line'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()
    df['MACD_Histogram'] = df['MACD_Line'] - df['Signal_Line']
    df['MACD_Histogram_Slope'] = df['MACD_Histogram'].diff().fillna(0)
    df['MACD_cross_up'] = ((df['MACD_Histogram'].shift(1) < 0) & (df['MACD_Histogram'] > 0)).astype(int)
    df['MACD_cross_down'] = ((df['MACD_Histogram'].shift(1) > 0) & (df['MACD_Histogram'] < 0)).astype(int)
    df['MACD_bullish_cross'] = ((df['MACD_Line'].shift(1) < df['Signal_Line'].shift(1)) & (df['MACD_Line'] > df['Signal_Line'])).astype(int)
    df['MACD_histogram_above_zero'] = (df['MACD_Histogram'] > 0).astype(int)

    # --- ë³µí•© ì‹œê·¸ë„ ---
    df['USD_down_MACD_up'] = ((df['USD_KRW_DEVIATION'] < -0.002) & (df['MACD_cross_up'] == 1)).astype(int)
    df['Volume_MACD_Combo'] = ((df['Volume_jump'] == 1) & (df['MACD_bullish_cross'] == 1)).astype(int)
    df['Composite_Bullish_Signal'] = (
        df[['USD_down_MACD_up', 'Strong_Trend', 'Volume_MACD_Combo']].sum(axis=1) >= 2
    ).astype(int)

    # --- Bollinger Bands ---
    df['BB_MID'] = df['Close'].rolling(20).mean()
    df['BB_STD'] = df['Close'].rolling(20).std()
    df['BB_UPPER'] = df['BB_MID'] + 2 * df['BB_STD']
    df['BB_LOWER'] = df['BB_MID'] - 2 * df['BB_STD']
    df['BB_PCT'] = (df['Close'] - df['BB_LOWER']) / (df['BB_UPPER'] - df['BB_LOWER'] + 1e-5)

    # --- Stochastic Oscillator ---
    low_min = df['Low'].rolling(window=14).min()
    high_max = df['High'].rolling(window=14).max()
    df['Stoch_K'] = 100 * (df['Close'] - low_min) / (high_max - low_min + 1e-5)
    df['Stoch_D'] = df['Stoch_K'].rolling(window=3).mean()

    # --- ì‹œê°€/ê³ ì € ê¸°ë°˜ í”¼ì²˜ ---
    df['Gap_Up'] = ((df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1) > 0.02).astype(int)
    df['Gap_Down'] = ((df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1) < -0.02).astype(int)
    df['Close_to_High'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'] + 1e-5)
    df['Intraday_Range'] = (df['High'] - df['Low']) / df['Open']
    df['Bullish_Candle'] = ((df['Close'] > df['Open']) & (df['Close_to_High'] > 0.7)).astype(int)
    df['Bearish_Candle'] = ((df['Close'] < df['Open']) & (df['Close_to_High'] < 0.3)).astype(int)

    # --- ë°˜ë“± ì‹œë‚˜ë¦¬ì˜¤ ---
    df['Rebound_from_low'] = ((df['Price_near_low_20d'] == 1) & (df['Close_RET'] > 0)).astype(int)
    
    # ê²°ì¸¡ê°’ ì œê±°
    df.dropna(subset=FEATURE_COLUMNS, inplace=True)
    # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    df.sort_values('Date', inplace=True)
    return df
# ------------------- ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ -------------------
def prepare_sequences(features, close_prices, target_percent):
    sequences, targets = [], []
    max_i = len(features) - SEQ_LEN 
    for i in range(max_i):
        window = features[i: i + SEQ_LEN]
        base_price = close_prices[i + SEQ_LEN - 1] # 1ì¼ ì „
        future_price = close_prices[i + SEQ_LEN]   # ì˜¤ëŠ˜
        if future_price >= base_price * (1 + target_percent):
            label = 0  # ìƒìŠ¹
        elif future_price <= base_price * (1 - target_percent):
            label = 1  # í•˜ë½
        else:
            continue
        sequences.append(window)
        targets.append(label)
    return np.array(sequences), np.array(targets)


# ------------------- ëª¨ë¸ ì •ì˜ -------------------
class StockModel(nn.Module):
    def __init__(self, input_size, hidden_size=32, dropout=0.3, drop_features=None, mask_scale=0.3):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.seq_len = SEQ_LEN

        self.drop_features = drop_features if drop_features is not None else []
        self.mask_scale = mask_scale

        self.global_dropout = nn.Dropout(p=dropout)

        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
        self.layernorm = nn.LayerNorm(hidden_size)  # LayerNorm ì¶”ê°€

        self.fc1 = nn.Linear(hidden_size, 32)
        self.gelu = nn.GELU()
        self.fc2 = nn.Linear(32, 2)

    def forward(self, x):
        # x shape: (batch_size, seq_len, feature_dim)

        if self.drop_features:
            x = x.clone()
            for idx in self.drop_features:
                x[:, :, idx] = x[:, :, idx] * self.mask_scale

        out, _ = self.gru(x)             # (batch, seq_len, hidden_size)
        out = out[:, -1, :]              # ë§ˆì§€ë§‰ ì‹œì ë§Œ
        out = self.layernorm(out)        # LayerNorm ì ìš©
        out = self.fc1(out)
        out = self.gelu(out)
        out = self.global_dropout(out)
        out = self.fc2(out)
        return out

# ------------------- ìŠ¤ì¼€ì¼ë§ -------------------
def scale_features(df, scalers): 
    if df.empty:
        raise ValueError("[scale_features] ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    parts = []
    if 'minmax' in scalers:
        parts.append(scalers['minmax'].transform(df[MINMAX_COLS]))
    if 'standard' in scalers:
        parts.append(scalers['standard'].transform(df[STANDARD_COLS]))
    if BINARY_COLS:
        parts.append(df[BINARY_COLS].values)
    return np.concatenate(parts, axis=1)

# ------------------- í•™ìŠµ í•¨ìˆ˜ -------------------
def train_model(df_train, early_stopping_patience=3):
    # --- 1. ê²€ì¦ ëˆ„ìˆ˜ ë°©ì§€: í•™ìŠµ ë°ì´í„° ì• 70%ë§Œìœ¼ë¡œ ìŠ¤ì¼€ì¼ëŸ¬ fit ---
    split_idx = int(len(df_train) * 0.7)
    df_train_feat = df_train.iloc[:split_idx]  # scaler í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°

    scalers = {}
    if MINMAX_COLS:
        scalers['minmax'] = MinMaxScaler().fit(df_train_feat[MINMAX_COLS])
    if STANDARD_COLS:
        scalers['standard'] = StandardScaler().fit(df_train_feat[STANDARD_COLS])

    # ì „ì²´ df_trainì— ìŠ¤ì¼€ì¼ëŸ¬ ì ìš©
    features = scale_features(df_train, scalers)

    # ì‹œí€€ìŠ¤ ë° ë ˆì´ë¸” ìƒì„±
    X_seq, y = prepare_sequences(features, df_train['Close'].values, TARGET_PERCENT)
    if len(y) < 100:
        return None, scalers

    # --- 2. train/val split (ì• 70%: í•™ìŠµ, ë’¤ 30%: ê²€ì¦) ---
    split_idx = int(len(y) * 0.7)
    X_train, X_val = X_seq[:split_idx], X_seq[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]

    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))
    val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)

    bad_feature_names = []
    bad_feature_idxs = [FEATURE_COLUMNS.index(name) for name in bad_feature_names if name in FEATURE_COLUMNS]

    model = StockModel(input_size=X_seq.shape[2], drop_features=bad_feature_idxs).to(device)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    weight_tensor = torch.tensor([1.0, 1.0]).to(device)
    criterion = nn.CrossEntropyLoss(weight=weight_tensor)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)

    best_val_loss = float('inf')
    best_state = None
    epochs_no_improve = 0

    for epoch in range(EPOCHS):
        # --- train ---
        model.train()
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            loss = criterion(model(xb), yb)
            loss.backward()
            optimizer.step()

        # --- validation ---
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb.to(device), yb.to(device)
                logits = model(xb)
                val_loss += criterion(logits, yb).item() * xb.size(0)
        val_loss /= len(val_ds)

        # scheduler step
        scheduler.step(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            epochs_no_improve = 0
        else:
            epochs_no_improve += 1
        if epochs_no_improve >= early_stopping_patience:
            break

    if best_state is not None:
        model.load_state_dict(best_state)
    return model, scalers

# ------------------- í•™ìŠµ, ì˜ˆì¸¡, í‰ê°€, ë§¤ìˆ˜ í›„ë³´ -------------------
def process_code_for_date(args):
    code, data, date = args
    df = data['df'] # ì „ì²˜ë¦¬ëœ ì£¼ê°€ ë°ì´í„°
    
    # 1) í•™ìŠµìš© ê¸°ê°„ ì„¤ì •
    train_end = date  # ì˜ˆì¸¡ ë‹¹ì¼ ì „ë‚ ê¹Œì§€ë§Œ í•™ìŠµì— ì‚¬ìš©
    train_start = train_end - pd.DateOffset(years=TRAIN_YEARS) 
    df_train = df[(df['Date']>=train_start) & (df['Date'] < train_end)]

    # 2) ëª¨ë¸ í•™ìŠµ
    model, scalers = train_model(df_train)
    if model is None:
        return code, {}

    # 3) ìµœì‹  ì‹œí€€ìŠ¤ë¡œ ì˜ˆì¸¡
    window = df[df['Date'] < date].tail(SEQ_LEN) # ì…ë ¥ìš© ë°ì´í„° ë½‘ê¸°
    inp = scale_features(window, scalers) # ì •ê·œí™” (SEQ_LEN, feature_dim)
    inp = torch.tensor(inp, dtype=torch.float32).unsqueeze(0).to(device) # PyTorch í…ì„œë¡œ ë³€í™˜, ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, SEQ_LEN, feature_dim)
    # ì˜ˆì¸¡ ([prob_up, prob_down])
    with torch.no_grad():
        prob = torch.softmax(model(inp), dim=1).cpu().numpy()[0]

    result = {
        'model': model,
        'scalers': scalers,
        'last_pred_prob': prob
    }

    # 4) ì •ë‹µ ë ˆì´ë¸” 
    subset = df[df['Date'] < date]  # date í•˜ë£¨ ì „ê¹Œì§€ ë°ì´í„°
    if len(subset) >= 1:
        base_price = subset.iloc[-1]['Close'] # 1ì¼ ì „ ì¢…ê°€ 
        future_price = df.loc[df['Date'] == date, 'Close'].iloc[0] if date in df['Date'].values else None # ì˜¤ëŠ˜ ì¢…ê°€
        if future_price is not None:
            # ì •ë‹µ ë¼ë²¨
            if future_price >= base_price * (1 + TARGET_PERCENT):
                true_label = 0
            elif future_price <= base_price * (1 - TARGET_PERCENT):
                true_label = 1
            else:
                true_label = None

            if true_label is not None:
                # ì˜ˆì¸¡ thresholdë¡œ íŒë‹¨ 
                if prob[0] >= BUY_PROB_THRESHOLD:
                    pred_class = 0
                elif prob[1] >= SELL_PROB_THRESHOLD:
                    pred_class = 1
                else:
                    pred_class = None  # í™•ì‹  ì—†ëŠ” ì˜ˆì¸¡ì€ ë¬´ì‹œ
                # 2ì¼ ì „ â†’ 1ì¼ ì „ ë³€í™”ìœ¨, 3ì¼ ì „ â†’ 2ì¼ ì „ ë³€í™”ìœ¨
                prev1 = base_price
                prev2 = subset.iloc[-2]['Close']
                prev3 = subset.iloc[-3]['Close'] 
                
                pct_change   = prev1 / prev2 - 1
                pct_change_2 = prev2 / prev3 - 1

                result.update({
                    'true_label': true_label,
                    'pred_class':  pred_class,
                    'pct_change':  pct_change,
                    'pct_change_2': pct_change_2
                })
                    
    # ë§¤ìˆ˜ í›„ë³´
    if result.get('last_pred_prob') is not None and result.get('pct_change') is not None:
        if (result['last_pred_prob'][0] >= BUY_PROB_THRESHOLD):
            result['buy_candidate'] = {'price': window['Close'].iloc[-1], 'pct_change': result['pct_change']}

    return code, result

# ------------------- ì²­í¬ ì²˜ë¦¬ -------------------
def _process_chunk(codes_chunk, stock_models, date):
    chunk_results = {}
    for code in codes_chunk:
        res_code, res = process_code_for_date((code, stock_models[code], date))
        if res: # ê²°ê³¼ê°€ ìˆìœ¼ë©´ chunk_resultsì— ì €ì¥
            chunk_results[res_code] = res
    return chunk_results

# ------------------- ë°±í…ŒìŠ¤íŠ¸ -------------------
def run_backtest(preproc_dfs, test_dates):
    # ê° ì¢…ëª© ìƒíƒœ ì €ì¥
    stock_models = {code: {'df': df, 'model': None, 'scalers': None,
                            'shares': 0, 'buy_price': None,
                            'true': [], 'pred': [], 'trade_history': []}
                    for code, df in preproc_dfs.items()}
    total_cash = INITIAL_CAPITAL
    portfolio_values = []

    for idx, date in enumerate(tqdm(test_dates, desc='ë°±í…ŒìŠ¤íŠ¸')):
        # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ CHUNK ë‹¨ìœ„ë¡œ ë‚˜ëˆ”
        codes = list(stock_models.keys())
        chunks = [codes[i:i+CHUNK] for i in range(0, len(codes), CHUNK)]

        # ê° ì²­í¬ì— ëŒ€í•´ joblibìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰
        results_list = Parallel(
            n_jobs=N_CORE,      # ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ê°œìˆ˜
            backend='loky',     # í”„ë¡œì„¸ìŠ¤ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬
            prefer='processes', # í”„ë¡œì„¸ìŠ¤ë¥¼ ì„ í˜¸
            batch_size=1        # ê° í”„ë¡œì„¸ìŠ¤ê°€ ì²­í¬ í•˜ë‚˜ì”©ë§Œ ì²˜ë¦¬
        )(delayed(_process_chunk)(chunk, stock_models, date) for chunk in chunks)

        # ê²°ê³¼ ë³‘í•©
        buy_candidates = {}
        for res_dict in results_list:
            for code, res in res_dict.items():
                # ë³µì‚¬
                data = stock_models[code]
                # ëª¨ë¸ & ìŠ¤ì¼€ì¼ëŸ¬
                data['model'] = res['model']
                data['scalers'] = res['scalers']
                data['last_pred_prob'] = res['last_pred_prob']
                # ì •ë‹µ & ì˜ˆì¸¡
                if 'true_label' in res:
                    data['true'].append(res['true_label'])
                    data['pred'].append(res['pred_class'])
                    if 'pred_dates' not in data:
                        data['pred_dates'] = []
                    data['pred_dates'].append(date)
                    if 'probs' not in data:
                        data['probs'] = []
                    data['probs'].append(res['last_pred_prob'])                   
                # buy í›„ë³´
                if 'buy_candidate' in res:
                    buy_candidates[code] = res['buy_candidate']

        # 1) ë§¤ë„ ì‹œë®¬ë ˆì´ì…˜
        day_max = total_cash * 0.1
        per_max = day_max * 0.3

        for code, data in stock_models.items():
            shares = data.get('shares', 0)
            if shares <= 0 or data.get('buy_price') is None:
                continue
            # ë§¤ë„ íŒë‹¨ì„ í•˜ëŠ” ì˜¤ëŠ˜ ë‚ ì§œ ì „ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ df_histì— ì €ì¥(ë§¤ë„ íŒë‹¨)
            df_hist = data['df'][data['df']['Date'] < date]
            if df_hist.empty:
                continue
            last_price = df_hist['Close'].iloc[-1]
            buy_price = data['buy_price']
            pred_prob = data.get('last_pred_prob')
            # ì´ˆê¸°í™”
            sell_pct = 0; reason = None
            
            if last_price > buy_price:
                sell_pct = 100; reason = 'ì´ìµ'                
            elif last_price < buy_price:
                sell_pct = 100; reason = 'ì†í•´'          
                  
            # ì‹¤ì œ ë§¤ë„
            if sell_pct > 0:
                # ë§¤ë„ ìˆ˜ëŸ‰
                qty = int(shares * sell_pct / 100)
                if qty > 0:
                    # ë§¤ë„ ê¸ˆì•¡
                    proceeds = qty * last_price * (1 - FEE_RATE - TAX_RATE)
                    total_cash += proceeds
                    data['shares'] -= qty
                    profit_pct = (last_price * (1 - FEE_RATE - TAX_RATE)) / (buy_price * (1 + FEE_RATE)) - 1
                    # ë§¤ë„ ê¸°ë¡ ì—…ë°ì´íŠ¸
                    for trade in data['trade_history']:
                        # ì•„ì§ ë§¤ë„í•˜ì§€ ì•Šì€ ê±°ë˜ ì°¾ê¸°
                        if trade.get('sell_date') is None:
                            # ë§¤ë„ ìˆ˜ëŸ‰>=ë³´ìœ  ìˆ˜ëŸ‰: ì „ëŸ‰ ë§¤ë„ ì²˜ë¦¬
                            if qty >= trade['qty']:
                                trade['sell_date'] = date
                                trade['sell_price'] = last_price
                                trade['profit_pct'] = profit_pct
                                trade['sell_reason'] = reason
                                break
                            else: # ë§¤ë„ ìˆ˜ëŸ‰<ë³´ìœ  ìˆ˜ëŸ‰: ë¶€ë¶„ ë§¤ë„ ì²˜ë¦¬
                                trade['qty'] -= qty
                                data['trade_history'].append({
                                    'buy_date': trade['buy_date'],
                                    'buy_price': trade['buy_price'],
                                    'qty': qty,
                                    'sell_date': date,
                                    'sell_price': last_price,
                                    'profit_pct': profit_pct,
                                    'sell_reason': reason
                                })
                                break
        # 2) ë§¤ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
        if buy_candidates:
            # ì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ë¥  ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ í™•ë¥ ë¶€í„°)
            sorted_codes = sorted(
                buy_candidates.keys(),
                key=lambda c: stock_models[c]['last_pred_prob'][0],
                reverse=True
            )
            # ìƒìœ„ Nê°œ ì¢…ëª©ë§Œ ë½‘ì•„ì„œ dict ìƒì„±
            top_buy = {code: buy_candidates[code] for code in sorted_codes[:TOP_N_FOR_BUY]}
        else:
            top_buy = {}
        for code, info in top_buy.items():
            # ë§¤ìˆ˜ ì‹œì  ê°€ê²©(ì „ë‚  ì¢…ê°€)
            price = info["price"] 
            # ë§¤ìˆ˜ ìˆ˜ëŸ‰ 
            qty = int(per_max // (price * (1 + FEE_RATE))) 
            if qty <= 0:
                continue
            # ì‹¤ì œ ì´ ë§¤ìˆ˜ ë¹„ìš© ê³„ì‚° (ìˆ˜ìˆ˜ë£Œ í¬í•¨)
            cost = qty * price * (1 + FEE_RATE) 
            if cost > total_cash: # ìê¸ˆ ë¶€ì¡± ì‹œ ì´ ìë³¸ê¸ˆ í•œë„ ë‚´ì—ì„œ ë‹¤ì‹œ ìˆ˜ëŸ‰ ê³„ì‚°
                qty = int(total_cash // (price * (1 + FEE_RATE)))
                cost = qty * price * (1 + FEE_RATE)
            if qty <= 0:
                continue
            total_cash -= cost
            data = stock_models[code] # í•´ë‹¹ ì¢…ëª© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            # ì´ë¯¸ ë³´ìœ  ì¤‘ì´ë¼ë©´ í‰ê·  ë‹¨ê°€ ìƒˆë¡œ ê³„ì‚°
            if data['shares'] > 0 and data['buy_price'] is not None:
                prev_s, prev_p = data['shares'], data['buy_price']
                data['buy_price'] = (prev_p * prev_s + price * qty) / (prev_s + qty)
            else: # ì‹ ê·œ ë§¤ìˆ˜ë¼ë©´ ê·¸ëƒ¥ í˜„ì¬ ë§¤ìˆ˜ ê°€ê²©ìœ¼ë¡œ ì„¤ì •
                data['buy_price'] = price
            data['shares'] += qty
            data['trade_history'].append({
                'buy_date': date,
                'buy_price': price,
                'qty': qty,
                'sell_date': None,
                'sell_price': None,
                'profit_pct': None,
                'sell_reason': None
            })
        
        # 3) ê°•ì œ ì²­ì‚° (ë§ˆì§€ë§‰ ë‚ ì§œ)
        if idx == len(test_dates) - 1:
            for code, data in stock_models.items():
                shares = data.get('shares', 0)
                buy_price = data.get('buy_price')
                # ë³´ìœ  ì¤‘ì¼ ê²½ìš° ì²­ì‚° ì‹œì‘
                if shares > 0 and buy_price is not None:
                    # ë§ˆì§€ë§‰ ë‚ ì§œ ì¢…ê°€
                    price = data['df'][data['df']['Date'] <= date]['Close'].iloc[-1]
                    # ì „ëŸ‰ ë§¤ë„ ì‹œ ìˆ˜ìµê¸ˆ, ìˆ˜ìµë¥  ê³„ì‚°
                    proceeds = shares * price * (1 - FEE_RATE - TAX_RATE)
                    total_cash += proceeds
                    profit_pct = (price * (1 - FEE_RATE - TAX_RATE)) / (buy_price * (1 + FEE_RATE)) - 1
                    for trade in data['trade_history']:
                        if trade.get('sell_date') is None:
                            trade['sell_date'] = date
                            trade['sell_price'] = price
                            trade['profit_pct'] = profit_pct
                            trade['sell_reason'] = 'ê°•ì œì²­ì‚°'
                    data['shares'] = 0
                    data['buy_price'] = None
                    
        # 4) í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì—…ë°ì´íŠ¸
        current_value = total_cash
        for code, data in stock_models.items():
            shares = data.get('shares', 0)
            if shares > 0:
                price = data['df'][data['df']['Date'] <= date]['Close'].iloc[-1] # í˜„ì¬ê°€
                current_value += shares * price # í‰ê°€ê¸ˆì•¡(ë³´ìœ  ìˆ˜ëŸ‰ * í˜„ì¬ê°€) ëˆ„ì 
        portfolio_values.append(current_value)

    return stock_models, portfolio_values

# ------------------- ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥ -------------------
# ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™”
def plot_backtest_results(dates, values):
    plt.figure(figsize=(14,6))
    plt.plot(dates, values, label='ì´ ìì‚°')
    plt.title('ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ì˜ ì´ ìì‚°')
    plt.xlabel('ë‚ ì§œ')
    plt.ylabel('ì´ ìì‚° (ì›)')
    formatter = ticker.FuncFormatter(lambda x, _: f"{int(x):,}")
    plt.gca().yaxis.set_major_formatter(formatter)
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, 'ì´ ìì‚°.png'), dpi=300)
    plt.close()

# ë§¤ë§¤ ë¡œê·¸ CSV ì €ì¥
def trade_log_csv(stock_models, filename="ë§¤ë§¤ ë¡œê·¸.csv"):
    records = []
    for code, data in stock_models.items():
        for t in data.get('trade_history', []):
            records.append({
                'code': code,
                'buy_date': t.get('buy_date'),
                'buy_price': t.get('buy_price'),
                'sell_date': t.get('sell_date'),
                'sell_price': t.get('sell_price'),
                'profit_pct': round(t.get('profit_pct', 0) * 100, 2) if t.get('profit_pct') is not None else None,
                'sell_reason': t.get('sell_reason')
            })
    df = pd.DataFrame(records)
    if not df.empty and 'buy_date' in df.columns:
        df = df.sort_values(by='buy_date')  # buy_date ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    df.to_csv(os.path.join(OUTPUT_DIR, filename), index=False, encoding='utf-8-sig')
    
# ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ Confusion Matrix
def plot_score(stock_models, filename="backtest_matrix.png"):
    all_true, all_pred = [], []
    for data in stock_models.values():
        true_list = data.get('true', [])
        pred_list = data.get('pred', [])
        filtered = [(t, p) for t, p in zip(true_list, pred_list) if t is not None and p is not None]
        for t, p in filtered:
            all_true.append(t)
            all_pred.append(p)

    if not all_true:
        print("ìœ íš¨í•œ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ì–´ confusion matrixë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    cm = confusion_matrix(all_true, all_pred, labels=[0, 1])
    labels = ["ìƒìŠ¹(0)", "í•˜ë½(1)"]
    total = cm.sum()

    # í™•ì¥ëœ í–‰ë ¬: 3x3 (ì˜ˆì¸¡ 2 + í•©ê³„) x (ì‹¤ì œ 2 + í•©ê³„)
    cm_extended = np.zeros((3, 3), dtype=int)
    cm_extended[:2, :2] = cm
    cm_extended[2, :2] = cm.sum(axis=0)         # ì—´ í•©ê³„ (ì‹¤ì œ ê¸°ì¤€)
    cm_extended[:2, 2] = cm.sum(axis=1)         # í–‰ í•©ê³„ (ì˜ˆì¸¡ ê¸°ì¤€)
    cm_extended[2, 2] = total                   # ì „ì²´ í•©ê³„

    # í¼ì„¼íŠ¸ ê³„ì‚°
    cm_percent = cm_extended / total

    fig, ax = plt.subplots(figsize=(7, 6))
    cmap = plt.cm.Blues

    for i in range(3):
        for j in range(3):
            value = cm_extended[i, j]
            if i < 2 and j < 2:  # Confusion matrix ë¶€ë¶„
                percent = cm_percent[i, j] * 100
                color = cmap(cm_percent[i, j])
                ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=True, color=color))
                ax.text(j + 0.5, i + 0.5, f"{value} ({percent:.1f}%)", 
                        va='center', ha='center', fontsize=11, color='black')
            else:  # í•©ê³„ ì˜ì—­
                ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='black'))
                ax.text(j + 0.5, i + 0.5, f"{value}", 
                        va='center', ha='center', fontsize=11, fontweight='bold')

    # ì¶• ì„¤ì •
    ax.set_xticks([0.5, 1.5, 2.5])
    ax.set_yticks([0.5, 1.5, 2.5])
    ax.set_xticklabels(labels + ['í•©ê³„'], fontsize=11)
    ax.set_yticklabels(labels + ['í•©ê³„'], fontsize=11)
    ax.set_xlim(0, 3)
    ax.set_ylim(0, 3)
    ax.invert_yaxis()
    ax.set_title('ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ Confusion Matrix', fontsize=14)
    ax.set_xlabel('ì‹¤ì œ ë¼ë²¨', fontsize=12)
    ax.set_ylabel('ì˜ˆì¸¡ ë¼ë²¨', fontsize=12)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300)
    plt.close()

# ì˜¤ëŠ˜ ë§¤ìˆ˜í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
# ------------------- [predict] -------------------
def predict(engine=None):
    """
    ì˜¤ëŠ˜ ë§¤ìˆ˜ í›„ë³´ CSVë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•œë‹¤.
    """
    today_date = pd.Timestamp.today().normalize()
    output_path = os.path.join(OUTPUT_DIR, "buy_list.csv")  

    if engine is None:
        engine = get_engine()
    
    limit = 200
    codes = pd.read_sql(f"SELECT DISTINCT Code FROM stock_data LIMIT {limit}", engine)['Code'].tolist()
    market_idx_df = load_market_index(engine)

    buy_candidates = []
    for code in tqdm(codes, desc="ì‹¤ì‹œê°„ ë§¤ìˆ˜ í›„ë³´ ì˜ˆì¸¡"):
        try:
            df_stock = load_stock_data(code, engine)
            df_full = df_stock.merge(market_idx_df, on='Date', how='left')
            df = engineer_features(df_full)

            train_end = today_date
            train_start = train_end - pd.DateOffset(years=TRAIN_YEARS)
            df_train = df[(df['Date'] >= train_start) & (df['Date'] < train_end)]

            model, scalers = train_model(df_train)
            if model is None:
                continue

            window = df[df['Date'] < today_date].tail(SEQ_LEN)
            if len(window) < SEQ_LEN:
                continue

            inp = scale_features(window, scalers)
            inp_tensor = torch.tensor(inp, dtype=torch.float32).unsqueeze(0).to(device)

            with torch.no_grad():
                prob = torch.softmax(model(inp_tensor), dim=1).cpu().numpy()[0]

            if prob[0] >= BUY_PROB_THRESHOLD:
                buy_candidates.append({
                    'ì¢…ëª©ì½”ë“œ': str(code).zfill(6),
                    'ìƒìŠ¹í™•ë¥ ': round(prob[0], 3),
                    'prob_down': round(prob[1], 3),
                    'price': window['Close'].iloc[-1]
                })

        except Exception as e:
            print(f"âŒ [predict] {code} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    # âœ… í™•ë¥  ê¸°ì¤€ ì •ë ¬ í›„ ìƒìœ„ TOP_N
    top_candidates = sorted(buy_candidates, key=lambda x: x['ìƒìŠ¹í™•ë¥ '], reverse=True)
    top_candidates = top_candidates[:TOP_N_FOR_BUY]

    # âœ… í•­ìƒ CSV ì €ì¥
    df_out = pd.DataFrame(top_candidates)
    df_out.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ“ [predict] ë§¤ìˆ˜ í›„ë³´ CSV ì €ì¥ ì™„ë£Œ: {output_path} (ì´ {len(df_out)}ê±´)")

    return top_candidates

def get_today_candidates(engine=None):
    """
    âœ… buy_list.csvë¥¼ ì•ˆì „í•˜ê²Œ ì½ì–´ì„œ ì¢…ëª©ì½”ë“œê°€ í•­ìƒ ë¬¸ìì—´ 6ìë¦¬ë¡œ ìœ ì§€ë˜ë„ë¡ í•œë‹¤.
    âœ… ë§¤ìˆ˜ì œì•ˆ ì»¬ëŸ¼ì´ 'ë§¤ìˆ˜'ì¸ ê²ƒë§Œ í•„í„°ë§í•œë‹¤.
    """
    df = pd.read_csv(
        "rule_2_ê²°ê³¼/buy_list.csv",
        dtype={'ì¢…ëª©ì½”ë“œ': str}   # â† í•µì‹¬! ì¢…ëª©ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ ê°•ì œ!
    )
    # ë§Œì•½ buy_list.csvì— 'ë§¤ìˆ˜ì œì•ˆ' ì»¬ëŸ¼ì´ ìˆë‹¤ë©´
    if 'ë§¤ìˆ˜ì œì•ˆ' in df.columns:
        df = df[df['ë§¤ìˆ˜ì œì•ˆ'] == 'ë§¤ìˆ˜']  # âœ”ï¸ 'ë§¤ìˆ˜'ë§Œ ì¶”ì¶œ

    print(f"âœ… [get_today_candidates] ë¶ˆëŸ¬ì˜¨ í›„ë³´ ìˆ˜: {len(df)}")
    print(df[['ì¢…ëª©ì½”ë“œ', 'ìƒìŠ¹í™•ë¥ ']])  # ë””ë²„ê¹… ì¶œë ¥
    return df.to_dict(orient="records")
# ------------------- [main] -------------------
def main():
    eng = get_engine()

    # ì¢…ëª© ë¡œë”©, ë°ì´í„° ì „ì²˜ë¦¬ ë“±
    codes = pd.read_sql(f"SELECT DISTINCT Code FROM stock_data LIMIT {STOCK_NUMBER}", eng)['Code'].tolist()
    market_idx_df = load_market_index(eng)
    preproc_dfs = {}
    for code in codes:
        df_stock = load_stock_data(code, eng)
        df_full = df_stock.merge(market_idx_df, on='Date', how='left')
        preproc_dfs[code] = engineer_features(df_full)

    # ë°±í…ŒìŠ¤íŠ¸ êµ¬ê°„
    dates_df = pd.read_sql(f"SELECT Date FROM stock_data WHERE Code='{codes[0]}' ORDER BY Date", eng, parse_dates=['Date'])
    start_idx = dates_df[dates_df['Date'] >= BACKTEST_START_DATE].index[0]
    test_dates = dates_df['Date'].iloc[start_idx : start_idx + TEST_PERIOD_DAYS]

    # ë°±í…ŒìŠ¤íŠ¸
    stock_models, portfolio_values = run_backtest(preproc_dfs, test_dates)

    # ê²°ê³¼ ì €ì¥
    plot_backtest_results(test_dates, portfolio_values)
    plot_score(stock_models)
    trade_log_csv(stock_models)

    print("âœ… ë°±í…ŒìŠ¤íŠ¸ ë° í›„ì²˜ë¦¬ ì™„ë£Œ!")

    # âœ… ë°±í…ŒìŠ¤íŠ¸ í›„ ì‹¤ì‹œê°„ í›„ë³´ ìƒì„±ê¹Œì§€
    print("\nğŸ§  ì‹¤ì‹œê°„ ë§¤ìˆ˜ í›„ë³´ ì˜ˆì¸¡ ì¤‘...")
    predict(eng)
    print("âœ… [main] buy_list.csv ìµœì‹ í™” ì™„ë£Œ!")

if __name__ == '__main__':
    print("âš¡ rule_2.py ì§ì ‘ ì‹¤í–‰ë¨: main() ì‹œì‘!")
    main()
