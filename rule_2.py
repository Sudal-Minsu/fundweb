import os
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from tqdm import tqdm
from sqlalchemy import create_engine
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from joblib import Parallel, delayed
import multiprocessing as mp
import hashlib, struct
from config import DB_CONFIG

# ------------------- ì„¤ì • -------------------
TRAIN_YEARS = 12
BACKTEST_START_DATE = pd.to_datetime("2024-07-11")
TEST_PERIOD_DAYS = 300
SEQ_LEN = 5
BATCH_SIZE = 32
LEARNING_RATE = 0.0005
EPOCHS = 20
VAL_LOSS_THRESHOLD = 0.693
PERCENT = 5   

# ë³‘ë ¬ ì„¤ì •
N_CORE = max(1, mp.cpu_count() - 1) # N_CORE = 5

# í°íŠ¸ ì„¤ì •
font_path = "C:/Windows/Fonts/malgun.ttf"
font_name = fm.FontProperties(fname=font_path).get_name()
plt.rcParams['font.family'] = font_name
plt.rcParams['axes.unicode_minus'] = False

# ì¶œë ¥ í´ë” ì„¤ì •
OUTPUT_DIR = "rule_2_ê²°ê³¼"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ë³‘ë ¬ í™˜ê²½ì˜ ë¹„ê²°ì •ì„± ë°©ì§€
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'

# PyTorch ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
torch.use_deterministic_algorithms(True)

# ì¢…ëª© ì½”ë“œë³„ë¡œ í•­ìƒ ê°™ì€ ì‹œë“œë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í•´ì‹œ ê¸°ë°˜ ì‹œë“œ í•¨ìˆ˜
def code_to_seed(code: str, base=42):
    # MD5 í•´ì‹œ â†’ int â†’ % 10_000_000
    h = hashlib.md5(code.encode('utf-8')).digest()
    return base + (struct.unpack_from(">I", h)[0] % 10_000_000)

# ê³ ì • ì‹œë“œ ì„¤ì •
random.seed(42)
np.random.seed(42)

# ì¥ì¹˜ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

# ------------------- í”¼ì²˜ ì •ì˜ -------------------
STANDARD_COLS = [
    # ë³€í™”ëŸ‰
    'Close_RET',
    'USD_KRW_RET',
    'KOSPI_RET',
    'KOSDAQ_RET',
]

MINMAX_COLS = [
    # ê¸°ë³¸ê°’
    'Close',
    'Open',
    'High',
    'Low',
    'Volume',
    'TradingValue',
]

CONTINUOUS_COLS = STANDARD_COLS + MINMAX_COLS 
FEATURE_COLUMNS = CONTINUOUS_COLS

# ------------------- DB & ë°ì´í„° ë¡œë”© -------------------
def get_engine():
    return create_engine(
        f"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
    )

def load_stock_data(code, engine):
    q = f"SELECT Date, Open, High, Low, Close, Volume FROM stock_data WHERE Code='{code}' ORDER BY Date"
    df = pd.read_sql(q, engine, parse_dates=['Date'])
    df['Code'] = code
    return df

def load_market_index(engine):
    q = "SELECT Date, IndexType, Close FROM market_index"
    df = pd.read_sql(q, engine, parse_dates=['Date'])
    return df.pivot(index='Date', columns='IndexType', values='Close').reset_index()

# ------------------- ì „ì²˜ë¦¬ ê³µí†µ -------------------
def engineer_features(df):
    df = df.sort_values('Date').reset_index(drop=True)
    # --- ê¸°ë³¸ ì •ë¦¬ ---
    df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce').fillna(0)
    df['Close_RET'] = df['Close'].pct_change().fillna(0)
    df['TradingValue'] = df['Close'] * df['Volume']
    
    # --- ê±°ì‹œ ê²½ì œ ë³€ìˆ˜ ì „ì²˜ë¦¬ ---
    df[['KOSPI','KOSDAQ','USD_KRW','US_RATE']] = df[['KOSPI','KOSDAQ','USD_KRW','US_RATE']].ffill().fillna(0)
    df['USD_KRW_RET'] = df['USD_KRW'].pct_change().fillna(0)
    df['KOSPI_RET'] = df['KOSPI'].pct_change().fillna(0)
    df['KOSDAQ_RET'] = df['KOSDAQ'].pct_change().fillna(0)
    
    # ê²°ì¸¡ê°’ ì œê±°
    df = df.replace([np.inf, -np.inf], np.nan)
    df.dropna(subset=FEATURE_COLUMNS, inplace=True)
    # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    df.sort_values('Date', inplace=True)
    return df
<<<<<<< HEAD
# ------------------- ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ -------------------
def prepare_sequences(features, close_prices, target_percent):
    sequences, targets = [], []
    max_i = len(features) - SEQ_LEN 
    for i in range(max_i):
        window = features[i: i + SEQ_LEN]
        base_price = close_prices[i + SEQ_LEN - 1] # 1ì¼ ì „
        future_price = close_prices[i + SEQ_LEN]   # ì˜¤ëŠ˜
        if future_price >= base_price * (1 + target_percent):
            label = 0  # ìƒìŠ¹
        elif future_price <= base_price * (1 - target_percent):
            label = 1  # í•˜ë½
        else:
            continue
        sequences.append(window)
        targets.append(label)
    return np.array(sequences), np.array(targets)

=======
>>>>>>> b93f38f25dd66574b21cd9c803b112d8e96757dc

# ------------------- ëª¨ë¸ ì •ì˜ -------------------
class StockModel(nn.Module):
    def __init__(self, input_size, hidden_size=32, dropout=0.3):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size

        self.global_dropout = nn.Dropout(p=dropout)
        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
        self.layernorm = nn.LayerNorm(hidden_size)
        self.fc1 = nn.Linear(hidden_size, 32)
        self.gelu1 = nn.GELU()
        self.fc_middle = nn.Linear(32, 16)  
        self.gelu2 = nn.GELU()
        self.fc2 = nn.Linear(16, 2)        

    def forward(self, x):
        # x: (batch, seq_len, feature_dim)
        gru_out, _ = self.gru(x)         # gru_out: (batch, seq_len, hidden_size)
        out = gru_out[:, -1, :]          # ë§ˆì§€ë§‰ ì‹œì ì˜ output ì„ íƒ (batch, hidden_size)

        out = self.layernorm(out)
        out = self.fc1(out)
        out = self.gelu1(out)
        out = self.fc_middle(out)        
        out = self.gelu2(out)
        out = self.global_dropout(out)
        out = self.fc2(out)
        return out

<<<<<<< HEAD
=======
# ------------------- ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ -------------------
def prepare_sequences(features, close_prices, target_percent=0.02):
    sequences, targets = [], []
    max_i = len(features) - SEQ_LEN 
    for i in range(max_i):
        window = features[i: i + SEQ_LEN]
        base_price = close_prices[i + SEQ_LEN - 1]
        future_price = close_prices[i + SEQ_LEN]
        if future_price >= base_price * (1 + target_percent):
            label = 0  # ìƒìŠ¹
        elif future_price <= base_price * (1 - target_percent):
            label = 1  # í•˜ë½
        else:
            continue
        sequences.append(window)
        targets.append(label)
    return np.array(sequences), np.array(targets)

>>>>>>> b93f38f25dd66574b21cd9c803b112d8e96757dc
# ------------------- ìŠ¤ì¼€ì¼ë§ -------------------
def scale_features(df, scalers): 
    if df.empty:
        raise ValueError("[scale_features] ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    parts = []
    if 'minmax' in scalers:
        parts.append(scalers['minmax'].transform(df[MINMAX_COLS]))
    if 'standard' in scalers:
        parts.append(scalers['standard'].transform(df[STANDARD_COLS]))
    return np.concatenate(parts, axis=1)

# ------------------- ì‹ ë¢°ë„ ì„ê³„ê°’ ê³„ì‚° -------------------
def compute_confidence_threshold(model, val_loader, percentile=PERCENT):
    confidences = [] # ê²€ì¦ì…‹ì˜ ê° ìƒ˜í”Œë³„ ëª¨ë¸ì˜ ìµœëŒ€ í™•ì‹ ë„(softmax ìµœëŒ€ê°’)â€ë¥¼ ì €ì¥
    model.eval()
    with torch.no_grad():
        for xb, yb in val_loader:
            xb = xb.to(device)
            probs = torch.softmax(model(xb), dim=1)
            max_conf = probs.max(dim=1)[0].cpu().numpy()
            confidences.extend(max_conf)
    if not confidences:
        return 1.0  # fallback, ì§‘ê³„ ë¶ˆê°€ ìƒí™©
    target_percentile = 100 - percentile
    return np.percentile(confidences, target_percentile)

# ------------------- í•™ìŠµ í•¨ìˆ˜ -------------------
def train_model(df_train, code=None, conf_percentile=PERCENT):
    
    # ì¢…ëª©ë³„ ì‹œë“œ ì„¤ì • (ê°™ì€ ì¢…ëª©ì´ë©´ í•­ìƒ ê°™ì€ ì‹œë“œ)
    seed = code_to_seed(code)
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    # 1) ê²€ì¦ ëˆ„ìˆ˜ ë°©ì§€: í•™ìŠµ ë°ì´í„° ì• 70%ë§Œìœ¼ë¡œ ìŠ¤ì¼€ì¼ëŸ¬ fit ---
    split_idx = int(len(df_train) * 0.7)
    df_train_feat = df_train.iloc[:split_idx]  # scaler í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°

    scalers = {}
    if MINMAX_COLS:
        scalers['minmax'] = MinMaxScaler().fit(df_train_feat[MINMAX_COLS])
    if STANDARD_COLS:
        scalers['standard'] = StandardScaler().fit(df_train_feat[STANDARD_COLS])

    # ì „ì²´ df_trainì— ìŠ¤ì¼€ì¼ëŸ¬ ì ìš©
    features = scale_features(df_train, scalers)

    # ì‹œí€€ìŠ¤ ë° ë ˆì´ë¸” ìƒì„±
    X_seq, y = prepare_sequences(features, df_train['Close'].values)
    if len(y) < 100:
        return None, scalers

    # 2) train/val split (ì• 70%: í•™ìŠµ, ë’¤ 30%: ê²€ì¦) ---
    split_idx = int(len(y) * 0.7)
    X_train, X_val = X_seq[:split_idx], X_seq[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]

    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))
    val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))
    g = torch.Generator()
    g.manual_seed(seed + 12345)
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, generator=g)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
    
    model = StockModel(input_size=X_seq.shape[2]).to(device)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    criterion = nn.CrossEntropyLoss()
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)

    # 3) í•™ìŠµ ë£¨í”„
    best_val_loss = float('inf')
    best_state = None
    epochs_no_improve = 0
    early_stopping_patience = 3
    
    for epoch in range(EPOCHS):
        # train
        model.train()
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            loss = criterion(model(xb), yb)
            loss.backward()
            optimizer.step()

        # validation
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb.to(device), yb.to(device)
                logits = model(xb)
                val_loss += criterion(logits, yb).item() * xb.size(0)
        val_loss /= len(val_ds)

        # scheduler step
        scheduler.step(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            epochs_no_improve = 0
        else:
            epochs_no_improve += 1
        if epochs_no_improve >= early_stopping_patience:
            break

    if best_state is not None:
        model.load_state_dict(best_state)
    # Î± ê³„ì‚°
    alpha = compute_confidence_threshold(model, val_loader, percentile=conf_percentile)
    return model, scalers, best_val_loss, alpha

# ------------------- í•™ìŠµ, ì˜ˆì¸¡, í‰ê°€, ë§¤ìˆ˜ í›„ë³´ -------------------
def process_code_for_date(args):
    code, data, date, conf_percentile = args
    df = data['df'] # ì „ì²˜ë¦¬ëœ ì£¼ê°€ ë°ì´í„°
    
    # 1) í•™ìŠµìš© ê¸°ê°„ ì„¤ì •
    train_end = date # ì˜ˆì¸¡ ë‹¹ì¼ ì „ë‚ ê¹Œì§€ë§Œ í•™ìŠµì— ì‚¬ìš©
    train_start = train_end - pd.DateOffset(years=TRAIN_YEARS)
    df_train = df[(df['Date'] >= train_start) & (df['Date'] < train_end)]

    # 2) ëª¨ë¸ í•™ìŠµ
    model, scalers, best_val, alpha = train_model(df_train, code=code, conf_percentile=conf_percentile)
    if model is None or best_val is None or best_val >= VAL_LOSS_THRESHOLD:
        return code, {}

    # 3) ìµœì‹  ì‹œí€€ìŠ¤ë¡œ ì˜ˆì¸¡
    window = df[df['Date'] < date].tail(SEQ_LEN) # ì…ë ¥ìš© ë°ì´í„° ë½‘ê¸°
    inp = scale_features(window, scalers) # ì •ê·œí™”(SEQ_LEN, feature_dim)
    inp_tensor = torch.tensor(inp, dtype=torch.float32).unsqueeze(0).to(device) # PyTorch í…ì„œë¡œ ë³€í™˜, ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, SEQ_LEN, feature_dim)
    # ì˜ˆì¸¡([prob_up, prob_down])
    model.eval()
    with torch.no_grad():
        prob = torch.softmax(model(inp_tensor), dim=1).cpu().numpy()[0]

    subset = df[df['Date'] < date] # date í•˜ë£¨ ì „ê¹Œì§€ ë°ì´í„°

    # 4) ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬ 
    result = {}
    if date in df['Date'].values:
        future_price = df.loc[df['Date'] == date, 'Close'].iloc[0]
        base_price = subset.iloc[-1]['Close'] # 1ì¼ ì „ ì¢…ê°€
        true_label = None
        # ì •ë‹µ ë¼ë²¨
        if future_price > base_price:
            true_label = 0
        elif future_price < base_price:
            true_label = 1

        if true_label is not None:
            pred_class = None
            # threshold(Î±) ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡ ì¸ì •
            if max(prob) >= alpha:
                if prob[0] > prob[1]:
                    pred_class = 0
                    result = {'true_label': true_label, 'pred_class': pred_class}
                elif prob[1] > prob[0]:
                    pred_class = 1
                    result = {'true_label': true_label, 'pred_class': pred_class}
                else:
                    result = {}
            else:
                result = {}

    return code, result

# ------------------- í…ŒìŠ¤íŠ¸ -------------------
def run_test(preproc_dfs, test_dates, conf_percentile=PERCENT):
    # ê° ì¢…ëª© ìƒíƒœ ì €ì¥
    stock_models = {code: {
        'df': df,
        'true': [],
        'pred': []
    } for code, df in preproc_dfs.items()}

    for date in tqdm(test_dates, desc='í…ŒìŠ¤íŠ¸'):
        codes = list(stock_models.keys())
        # ì¢…ëª©ë³„ë¡œ ë°”ë¡œ ë³‘ë ¬ ì‹¤í–‰
        parallel_input = [(code, stock_models[code], date, conf_percentile) for code in codes]
        results = Parallel(
            n_jobs=N_CORE,
            backend='loky',
            prefer='processes'
        )(
            delayed(process_code_for_date)(args) for args in parallel_input
        )

        for code, res in results:
            if not res:
                continue
            data = stock_models[code]
            if 'true_label' in res:
                data['true'].append(res['true_label'])
                data['pred'].append(res.get('pred_class'))

    return stock_models

# í…ŒìŠ¤íŠ¸ ê¸°ê°„ Confusion Matrix
def plot_score(stock_models, filename="confusion_matrix.png"):
    all_true, all_pred = [], []
    for data in stock_models.values():
        true_list = data.get('true', [])
        pred_list = data.get('pred', [])
        for t, p in zip(true_list, pred_list):
            # t, p ëª¨ë‘ 0 ë˜ëŠ” 1ë§Œ í—ˆìš© 
            if t is not None and p in [0, 1]:
                all_true.append(t)
                all_pred.append(p)

    if not all_true:
        print("ìœ íš¨í•œ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ì–´ confusion matrixë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    label_names = ["ìƒìŠ¹(0)", "í•˜ë½(1)"]
    pred_names = ["ìƒìŠ¹(0)", "í•˜ë½(1)"]

    # 2x2 í–‰ë ¬
    cm = np.zeros((2, 2), dtype=int)
    for t, p in zip(all_true, all_pred):
        cm[t, p] += 1

    # í•©ê³„ ì¶”ê°€ëœ 3x3 í™•ì¥ í–‰ë ¬
    cm_extended = np.zeros((3, 3), dtype=int)
    cm_extended[:2, :2] = cm
    cm_extended[2, :2] = cm.sum(axis=0)    # ì˜ˆì¸¡ í´ë˜ìŠ¤ë³„ í•©ê³„
    cm_extended[:2, 2] = cm.sum(axis=1)    # ì‹¤ì œ í´ë˜ìŠ¤ë³„ í•©ê³„
    cm_extended[2, 2] = cm.sum()           # ì „ì²´ í•©ê³„

    fig, ax = plt.subplots(figsize=(7, 5))
    cmap = plt.cm.Blues

    # ì…€ ê·¸ë¦¬ê¸°
    for i in range(3):
        for j in range(3):
            value = cm_extended[i, j]
            if i < 2 and j < 2:
                percent = (cm[i, j] / cm.sum() * 100) if cm.sum() > 0 else 0.0
                scaled = 0.2 + 0.8 * (cm[i, j] / cm.sum()) if cm.sum() > 0 else 0.2
                color = cmap(scaled)
                ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=True, color=color))
                ax.text(j + 0.5, i + 0.5, f"{value}\n({percent:.1f}%)",
                        va='center', ha='center', fontsize=12, color='black')
            else:
                # í•©ê³„ í–‰/ì—´
                ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='black'))
                ax.text(j + 0.5, i + 0.5, f"{value}",
                        va='center', ha='center', fontsize=12, fontweight='bold')

    # ì¶• ë¼ë²¨
    ax.set_xticks([0.5, 1.5, 2.5])
    ax.set_yticks([0.5, 1.5, 2.5])
    ax.set_xticklabels(pred_names + ['í•©ê³„'], fontsize=13)
    ax.set_yticklabels(label_names + ['í•©ê³„'], fontsize=13)
    ax.set_xlabel('ì˜ˆì¸¡ ë¼ë²¨', fontsize=14)
    ax.set_ylabel('ì‹¤ì œ ë¼ë²¨', fontsize=14)

    ax.set_xlim(0, 3)
    ax.set_ylim(0, 3)
    ax.invert_yaxis()
    ax.set_title('Confusion Matrix', fontsize=16)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300)
    plt.close()
    print(f"Confusion matrix ì €ì¥ ì™„ë£Œ: {os.path.join(OUTPUT_DIR, filename)}")
    
# ì˜¤ëŠ˜ ë§¤ìˆ˜í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
<<<<<<< HEAD
# ------------------- [predict] -------------------
def predict(engine=None):
    """
    ì˜¤ëŠ˜ ë§¤ìˆ˜ í›„ë³´ CSVë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•œë‹¤.
    """
=======
def predict_today_candidates(engine=None):
>>>>>>> b93f38f25dd66574b21cd9c803b112d8e96757dc
    today_date = pd.Timestamp.today().normalize()
    output_path = os.path.join(OUTPUT_DIR, "buy_list.csv")  

    if engine is None:
        engine = get_engine()
    
    limit = 200
    codes = pd.read_sql(f"SELECT DISTINCT Code FROM stock_data LIMIT {limit}", engine)['Code'].tolist()
    market_idx_df = load_market_index(engine)

    buy_candidates = []
    for code in tqdm(codes, desc="ì‹¤ì‹œê°„ ë§¤ìˆ˜ í›„ë³´ ì˜ˆì¸¡"):
        try:
            df_stock = load_stock_data(code, engine)
            df_full = df_stock.merge(market_idx_df, on='Date', how='left')
            df = engineer_features(df_full)

            train_end = today_date
            train_start = train_end - pd.DateOffset(years=TRAIN_YEARS)
            df_train = df[(df['Date'] >= train_start) & (df['Date'] < train_end)]

            model, scalers, best_val, alpha = train_model(df_train, code=code, conf_percentile=PERCENT)
            if model is None or best_val is None or best_val >= VAL_LOSS_THRESHOLD:
                continue

            window = df[df['Date'] < today_date].tail(SEQ_LEN)
            if len(window) < SEQ_LEN:
                continue

            inp = scale_features(window, scalers)
            inp_tensor = torch.tensor(inp, dtype=torch.float32).unsqueeze(0).to(device)
            
            model.eval()
            with torch.no_grad():
                prob = torch.softmax(model(inp_tensor), dim=1).cpu().numpy()[0]

            if max(prob) >= alpha and prob[0] > prob[1]:
                buy_candidates.append({
<<<<<<< HEAD
                    'ì¢…ëª©ì½”ë“œ': str(code).zfill(6),
                    'ìƒìŠ¹í™•ë¥ ': round(prob[0], 3),
                    'prob_down': round(prob[1], 3),
                    'price': window['Close'].iloc[-1]
                })

        except Exception as e:
            print(f"âŒ [predict] {code} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    # âœ… í™•ë¥  ê¸°ì¤€ ì •ë ¬ í›„ ìƒìœ„ TOP_N
    top_candidates = sorted(buy_candidates, key=lambda x: x['ìƒìŠ¹í™•ë¥ '], reverse=True)
    top_candidates = top_candidates[:TOP_N_FOR_BUY]

    # âœ… í•­ìƒ CSV ì €ì¥
    df_out = pd.DataFrame(top_candidates)
=======
                    'ì¢…ëª©ì½”ë“œ': code,
                    'ìƒìŠ¹í™•ë¥ ': round(prob[0], 3)
                })
        except Exception:
            continue

    # í™•ë¥  ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    buy_candidates_sorted = sorted(buy_candidates, key=lambda x: x['ìƒìŠ¹í™•ë¥ '], reverse=True)

    # CSV ì €ì¥ (í›„ë³´ê°€ ì—†ì–´ë„ í—¤ë”ë§Œ ìˆëŠ” íŒŒì¼ ìƒì„±)
    df_out = pd.DataFrame(buy_candidates_sorted, columns=['ì¢…ëª©ì½”ë“œ', 'ìƒìŠ¹í™•ë¥ '])
>>>>>>> b93f38f25dd66574b21cd9c803b112d8e96757dc
    df_out.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ“ [predict] ë§¤ìˆ˜ í›„ë³´ CSV ì €ì¥ ì™„ë£Œ: {output_path} (ì´ {len(df_out)}ê±´)")

<<<<<<< HEAD
    return top_candidates

def get_today_candidates(engine=None):
    """
    âœ… buy_list.csvë¥¼ ì•ˆì „í•˜ê²Œ ì½ì–´ì„œ ì¢…ëª©ì½”ë“œê°€ í•­ìƒ ë¬¸ìì—´ 6ìë¦¬ë¡œ ìœ ì§€ë˜ë„ë¡ í•œë‹¤.
    âœ… ë§¤ìˆ˜ì œì•ˆ ì»¬ëŸ¼ì´ 'ë§¤ìˆ˜'ì¸ ê²ƒë§Œ í•„í„°ë§í•œë‹¤.
    """
    df = pd.read_csv(
        "rule_2_ê²°ê³¼/buy_list.csv",
        dtype={'ì¢…ëª©ì½”ë“œ': str}   # â† í•µì‹¬! ì¢…ëª©ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ ê°•ì œ!
    )
    # ë§Œì•½ buy_list.csvì— 'ë§¤ìˆ˜ì œì•ˆ' ì»¬ëŸ¼ì´ ìˆë‹¤ë©´
    if 'ë§¤ìˆ˜ì œì•ˆ' in df.columns:
        df = df[df['ë§¤ìˆ˜ì œì•ˆ'] == 'ë§¤ìˆ˜']  # âœ”ï¸ 'ë§¤ìˆ˜'ë§Œ ì¶”ì¶œ

    print(f"âœ… [get_today_candidates] ë¶ˆëŸ¬ì˜¨ í›„ë³´ ìˆ˜: {len(df)}")
    print(df[['ì¢…ëª©ì½”ë“œ', 'ìƒìŠ¹í™•ë¥ ']])  # ë””ë²„ê¹… ì¶œë ¥
    return df.to_dict(orient="records")
# ------------------- [main] -------------------
=======
    return buy_candidates_sorted
        
# ------------------- ë©”ì¸ -------------------
>>>>>>> b93f38f25dd66574b21cd9c803b112d8e96757dc
def main():
    eng = get_engine()
<<<<<<< HEAD

    # ì¢…ëª© ë¡œë”©, ë°ì´í„° ì „ì²˜ë¦¬ ë“±
    codes = pd.read_sql(f"SELECT DISTINCT Code FROM stock_data LIMIT {STOCK_NUMBER}", eng)['Code'].tolist()
=======
    
    # 2) ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë”©
    codes = pd.read_sql(f"SELECT DISTINCT Code FROM stock_data LIMIT {200}", eng)['Code'].tolist()
    
    # 3) ì „ì²´ ì¢…ëª© ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ 
>>>>>>> b93f38f25dd66574b21cd9c803b112d8e96757dc
    market_idx_df = load_market_index(eng)
    preproc_dfs = {}
    for code in codes:
        df_stock = load_stock_data(code, eng)
        df_full = df_stock.merge(market_idx_df, on='Date', how='left')
        preproc_dfs[code] = engineer_features(df_full)

    # ë°±í…ŒìŠ¤íŠ¸ êµ¬ê°„
    dates_df = pd.read_sql(f"SELECT Date FROM stock_data WHERE Code='{codes[0]}' ORDER BY Date", eng, parse_dates=['Date'])
    start_idx = dates_df[dates_df['Date'] >= BACKTEST_START_DATE].index[0]
    test_dates = dates_df['Date'].iloc[start_idx : start_idx + TEST_PERIOD_DAYS]

<<<<<<< HEAD
    # ë°±í…ŒìŠ¤íŠ¸
    stock_models, portfolio_values = run_backtest(preproc_dfs, test_dates)

    # ê²°ê³¼ ì €ì¥
    plot_backtest_results(test_dates, portfolio_values)
    plot_score(stock_models)
    trade_log_csv(stock_models)

    print("âœ… ë°±í…ŒìŠ¤íŠ¸ ë° í›„ì²˜ë¦¬ ì™„ë£Œ!")

    # âœ… ë°±í…ŒìŠ¤íŠ¸ í›„ ì‹¤ì‹œê°„ í›„ë³´ ìƒì„±ê¹Œì§€
    print("\nğŸ§  ì‹¤ì‹œê°„ ë§¤ìˆ˜ í›„ë³´ ì˜ˆì¸¡ ì¤‘...")
    predict(eng)
    print("âœ… [main] buy_list.csv ìµœì‹ í™” ì™„ë£Œ!")
=======
    # 5) ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    stock_models = run_test(preproc_dfs, test_dates, conf_percentile=PERCENT)

    # 6) ê²°ê³¼ ì €ì¥
    plot_score(stock_models)
    
    print("í…ŒìŠ¤íŠ¸ ë° í›„ì²˜ë¦¬ ì™„ë£Œ")
>>>>>>> b93f38f25dd66574b21cd9c803b112d8e96757dc

if __name__ == '__main__':
    print("âš¡ rule_2.py ì§ì ‘ ì‹¤í–‰ë¨: main() ì‹œì‘!")
    main()
