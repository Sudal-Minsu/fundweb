from flask import Flask, render_template, abort, jsonify, request, send_from_directory, redirect, url_for, Response
import os
import pymysql
import pandas as pd
from datetime import datetime
from auto_pipeline import run_auto_pipeline
from apscheduler.schedulers.background import BackgroundScheduler
import threading
from functions import read_trades_mysql, single_trade
from flask_sqlalchemy import SQLAlchemy
import matplotlib.pyplot as plt
import io
import yaml
import requests
from config import DB_CONFIG

app = Flask(__name__)
modeling_status = {"state": "idle", "metrics": {}, "plot_path": ""}
UPLOAD_BASE = os.path.join(app.root_path, "rule_2_ê²°ê³¼")

# DB ì„¤ì • (SQLiteë¡œ ê°„ë‹¨í•˜ê²Œ ì‹œì‘)
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///portfolio.db'
db = SQLAlchemy(app)

# DB ëª¨ë¸ ì •ì˜
class Portfolio(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    ticker = db.Column(db.String(20))
    weight = db.Column(db.Float)

with app.app_context():
    db.create_all()

trading_thread = None


def job_fetch_data():
    run_auto_pipeline()

scheduler = BackgroundScheduler()
scheduler.add_job(job_fetch_data, "cron", hour=9, minute=0)
scheduler.start()

@app.route('/ping')
def show_table():
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()

        # í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°
        cursor.execute("SELECT * FROM portfolio_summary")
        summary_rows = cursor.fetchall()

        # ë³´ìœ  ì¢…ëª©(holdings) ê°€ì ¸ì˜¤ê¸°
        cursor.execute("SELECT symbol, quantity, avg_price, current_price FROM holdings")
        holding_rows = cursor.fetchall()

    except Exception as e:
        print("âŒ DB ì˜¤ë¥˜ ë°œìƒ:", e)
        return f"<h2>DB ì—ëŸ¬: {e}</h2>"

    finally:
        if 'cursor' in locals(): cursor.close()
        if 'conn' in locals(): conn.close()

    return render_template('ping.html', data=summary_rows, holdings=holding_rows)

# ìë™ ì—…ë°ì´íŠ¸
with open("config/users.yaml", encoding="utf-8") as f:
    USERS = yaml.safe_load(f)

def generate_user_csv(user_id, config):
    headers = {"Authorization": f"Bearer {config['api_key']}"}
    url = "https://openapivts.koreainvestment.com:29443"
    r = requests.get(url, headers=headers)
    data = r.json()

    df = pd.DataFrame(data)
    today = datetime.date.today().strftime("%Y-%m-%d")

    user_dir = os.path.join("rule_2_ê²°ê³¼", user_id)
    os.makedirs(user_dir, exist_ok=True)

    file_path = os.path.join(user_dir, config["output"])
    df.to_csv(file_path, index=False, encoding="utf-8-sig")
    print(f"[{user_id}] {file_path} ì €ì¥ ì™„ë£Œ")

def daily_job():
    print("auto_pipeline ì‹¤í–‰ ì‹œì‘")
    run_auto_pipeline()
    print("auto_pipeline ì™„ë£Œ")

    print("ì‚¬ìš©ìë³„ CSV ìƒì„± ì‹œì‘")
    for user_id, cfg in USERS.items():
        try:
            generate_user_csv(user_id, cfg)
        except Exception as e:
            print(f"[ERROR] {user_id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)
    print("ì‚¬ìš©ìë³„ CSV ìƒì„± ì™„ë£Œ")

scheduler = BackgroundScheduler()
scheduler.add_job(daily_job, "cron", hour=9, minute=0)
scheduler.start()

@app.route("/upload/<user_id>", methods=["POST"])
def upload_csv(user_id):
    if "file" not in request.files:
        return jsonify({"error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"}), 400

    file = request.files["file"]
    user_dir = os.path.join(UPLOAD_BASE, user_id)
    os.makedirs(user_dir, exist_ok=True)

    save_path = os.path.join(user_dir, file.filename)
    file.save(save_path)

    return jsonify({"message": f"{file.filename} ì—…ë¡œë“œ ì„±ê³µ", "path": save_path})

#í™ˆ í˜ì´ì§€ ë¼ìš°íŠ¸
@app.route("/home")
def home():
    return render_template("home.html")

#í¬íŠ¸í´ë¦¬ì˜¤ í˜ì´ì§€ ë¼ìš°íŠ¸    
@app.route("/portfolio")
def portfolio():
    try:
        result_dir = os.path.join(app.root_path, "rule_2_ê²°ê³¼")
        holdings_path = os.path.join(result_dir, "holdings.csv")

        cand_names = ["portfolio_summary.csv", "portfolio.csv"]
        summary_path = None
        for name in cand_names:
            p = os.path.join(result_dir, name)
            if os.path.exists(p):
                summary_path = p
                break

        if not os.path.exists(holdings_path):
            return "<h2>holdings.csv íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</h2>"
        if summary_path is None:
            return "<h2>í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</h2>"

        try:
            df_h = pd.read_csv(holdings_path, encoding="utf-8-sig")
        except UnicodeDecodeError:
            df_h = pd.read_csv(holdings_path, encoding="cp949")
        df_h = df_h.fillna("")

        for col in ["ë³´ìœ ìˆ˜ëŸ‰", "ë§¤ì…ë‹¨ê°€", "í˜„ì¬ê°€"]:
            if col in df_h.columns:
                s = pd.to_numeric(df_h[col], errors="coerce")
                df_h[col] = s.map(lambda x: f"{int(x):,}" if pd.notna(x) else "")

        try:
            df_s = pd.read_csv(summary_path, encoding="utf-8-sig")
        except UnicodeDecodeError:
            df_s = pd.read_csv(summary_path, encoding="cp949")
        df_s = df_s.fillna("")

        for c in df_s.columns:
            s = pd.to_numeric(df_s[c], errors="coerce")
            if s.notna().any():
                df_s[c] = s.map(lambda x: f"{int(x):,}" if pd.notna(x) and float(x).is_integer() else (f"{x:,.2f}" if pd.notna(x) else ""))

        holdings_cols = df_h.columns.tolist()
        holdings_rows = df_h.to_dict(orient="records")
        summary_cols = df_s.columns.tolist()
        summary_rows = df_s.to_dict(orient="records")

        return render_template(
            "portfolio.html",
            holdings_cols=holdings_cols,
            holdings_rows=holdings_rows,
            summary_cols=summary_cols,
            summary_rows=summary_rows
        )
    except Exception as e:
        print(f"[ERROR] /portfolio ì‹¤íŒ¨: {e}")
        return f"<h2>/portfolio ë¡œë“œ ì‹¤íŒ¨: {e}</h2>"

# ëˆ„ì  ìˆ˜ìµë¥  ê·¸ë˜í”„ ë¡œë“œ
@app.route("/cumulative-returns")
def cumulative_returns():
    try:
        result_dir = os.path.join(app.root_path, "rule_2_ê²°ê³¼")
        file_path = os.path.join(result_dir, "ì´í‰ê°€ê¸ˆì•¡.csv")
        if not os.path.exists(file_path):
            return jsonify({"labels": [], "values": []})
        try:
            df = pd.read_csv(file_path, encoding="utf-8-sig")
        except UnicodeDecodeError:
            df = pd.read_csv(file_path, encoding="cp949")
        df.columns = df.columns.str.strip()
        if "loop" not in df.columns or "ì´í‰ê°€ê¸ˆì•¡" not in df.columns:
            return jsonify({"labels": [], "values": []})
        df["ì´í‰ê°€ê¸ˆì•¡"] = pd.to_numeric(df["ì´í‰ê°€ê¸ˆì•¡"], errors="coerce")
        df = df.dropna(subset=["ì´í‰ê°€ê¸ˆì•¡"])
        labels = df["loop"].astype(str).tolist()
        values = df["ì´í‰ê°€ê¸ˆì•¡"].astype(float).tolist()
        return jsonify({"labels": labels, "values": values})
    except Exception as e:
        print("[ERROR] cumulative-returns:", e)
        return jsonify({"labels": labels, "returns": values})

#forecast í˜ì´ì§€ ë¼ìš°íŠ¸
@app.route("/forecast")
def forecast():
    return render_template("forecast.html")

#ë¦¬í¬íŠ¸ í˜ì´ì§€ ë¼ìš°íŠ¸
@app.route("/strategy")
def strategy():
    return render_template("strategy.html")

# confusion matrix ë¡œë“œ
@app.route("/confusion-data")
def confusion_data():
    try:
        result_dir = os.path.join(app.root_path, "rule_2_ê²°ê³¼")
        file_path = os.path.join(result_dir, "confusion_matrix.csv")

        if not os.path.exists(file_path):
            print(f"[ERROR] confusion_matrix.csv íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
            return jsonify({"matrix": [], "total": 0})

        df = pd.read_csv(file_path, encoding="utf-8-sig")
        df.columns = df.columns.str.strip()
        df = df.rename(columns={
            df.columns[0]: "ì‹¤ì œ ë¼ë²¨",
            df.columns[1]: "ì˜ˆì¸¡ ë¼ë²¨",
            df.columns[2]: "í•©ê³„"
        })

        pivot = {
            (int(row["ì‹¤ì œ ë¼ë²¨"]), int(row["ì˜ˆì¸¡ ë¼ë²¨"])): int(row["í•©ê³„"])
            for _, row in df.iterrows()
        }

        matrix = [
            [pivot.get((0, 0), 0), pivot.get((0, 1), 0)],
            [pivot.get((1, 0), 0), pivot.get((1, 1), 0)],
        ]
        total = sum(sum(row) for row in matrix)

        return jsonify({
            "matrix": matrix,
            "total": total
        })

    except Exception as e:
        print(f"[ERROR] confusion_matrix.csv ë¡œë“œ ì‹¤íŒ¨: {e}")
        return jsonify({"matrix": [], "total": 0})

#ë§¤ë§¤ ë¡œê·¸ ë¡œë“œ
@app.route("/trade-log")
def trade_log():
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(base_dir, "trade_log.csv")
        if not os.path.exists(file_path):
            print(f"[ERROR] íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
            return jsonify([])
        df = pd.read_csv(file_path, encoding="utf-8-sig").fillna("")
        df["ê±°ë˜ì‹œê°„"] = pd.to_datetime(
            df["ê±°ë˜ì‹œê°„"].astype(str).str.strip(),
            format="%Y-%m-%d %H:%M:%S.%f",
            errors="coerce"
        )
        df["ê±°ë˜ì‹œê°„"] = df["ê±°ë˜ì‹œê°„"].dt.strftime("%Y-%m-%d %H:%M")
        df = df[df["ì£¼ë¬¸ê²°ê³¼"] == "ëª¨ì˜íˆ¬ì ë§¤ìˆ˜ì£¼ë¬¸ì´ ì™„ë£Œ ë˜ì—ˆìŠµë‹ˆë‹¤."]
        df = df.tail(10).iloc[::-1]
        selected_columns = [
            "ê±°ë˜ì‹œê°„",
            "ì¢…ëª©ì½”ë“œ",
            "í˜„ì¬ê°€",
            "ì£¼ë¬¸ìˆ˜ëŸ‰",
            "ì£¼ë¬¸ì¢…ë¥˜",
        ]
        df = df[selected_columns]
        return jsonify(df.to_dict(orient="records"))

    except Exception as e:
        print(f"[ERROR] trade_log.csv ë¡œë“œ ì‹¤íŒ¨: {e}")
        return jsonify([])

@app.route("/")
def root():
    return redirect("/home")

# ğŸ”¹ Flask ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="127.0.0.1", port=port, debug=False, use_reloader=False)