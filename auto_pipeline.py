from datetime import datetime
from crawler import crawl_all_pages
from sentiment import fetch_news_from_mysql, analyze_sentiment, update_sentiment_in_mysql
import time

def run_auto_pipeline():
    today = datetime.now().strftime('%Y-%m-%d')
    print(f"\nğŸ•’ {datetime.now().strftime('%H:%M:%S')} | ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    crawl_all_pages(today)

    print("ğŸ§  ê°ì„± ë¶„ì„ ì‹œì‘")
    news_data = fetch_news_from_mysql()
    if news_data:
        analyzed_data = [(analyze_sentiment(title), news_id) for news_id, title in news_data]
        update_sentiment_in_mysql(analyzed_data)
    else:
        print("ê°ì„± ë¶„ì„í•  ë‰´ìŠ¤ ì—†ìŒ")

    print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")

# ì‹¤í–‰
if __name__ == "__main__":
    run_auto_pipeline()     # ì‹œì‘ ì‹œ 1íšŒ ì‹¤í–‰